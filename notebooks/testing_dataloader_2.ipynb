{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "import PIL\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "from PIL import ImageFilter\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "def cifar_strong_transforms():\n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(32),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    return all_transforms\n",
    "\n",
    "\n",
    "def cifar_weak_transforms():\n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    return all_transforms\n",
    "\n",
    "\n",
    "def cifar_test_transforms():\n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    return all_transforms\n",
    "\n",
    "\n",
    "class CIFAR10C(CIFAR10):\n",
    "    def __init__(self, weak_transform, strong_transform, *args, **kwargs):\n",
    "        super(CIFAR10C, self).__init__(*args, **kwargs)\n",
    "        self.weak_transform = weak_transform\n",
    "        self.strong_transform = strong_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        xi = self.weak_transform(img)\n",
    "        xj = self.strong_transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        # Return label just for debugging\n",
    "        return xi, xj, target\n",
    "\n",
    "\n",
    "class LoaderCIFAR(object):\n",
    "    def __init__(self, file_path, download, batch_size, num_labeled, use_cuda):\n",
    "\n",
    "        kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "        # Get the datasets\n",
    "        train_labeled_dataset, train_unlabeled_dataset, test_dataset, labeled_ind, unlabeled_ind = self.get_dataset(file_path, download, num_labeled)\n",
    "        # Set the loaders\n",
    "        self.train_labeled = DataLoader(train_labeled_dataset, batch_size=batch_size, shuffle=False, sampler=SubsetRandomSampler(labeled_ind), **kwargs)\n",
    "        self.train_unlabeled = DataLoader(train_unlabeled_dataset, batch_size=batch_size, shuffle=False, sampler=SubsetRandomSampler(unlabeled_ind), **kwargs)\n",
    "\n",
    "        self.test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "        tmp_batch = self.test.__iter__().__next__()[0]\n",
    "        self.img_shape = list(tmp_batch.size())[1:]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_dataset(file_path, download, num_labeled):\n",
    "\n",
    "        num_labeled = 10\n",
    "\n",
    "        # transforms\n",
    "        weak_transform = cifar_weak_transforms()\n",
    "        strong_transform = cifar_strong_transforms()\n",
    "        test_transform = cifar_test_transforms()\n",
    "\n",
    "        # Training and Validation datasets\n",
    "        train_labeled_dataset = CIFAR10(root=file_path, train=True, download=download,\n",
    "                                        transform=weak_transform,\n",
    "                                        target_transform=None)\n",
    "        train_unlabeled_dataset = CIFAR10C(weak_transform=weak_transform, strong_transform=strong_transform,\n",
    "                                           root=file_path, train=True, download=download,\n",
    "                                           transform=None,\n",
    "                                           target_transform=None)\n",
    "\n",
    "        test_dataset = CIFAR10(root=file_path, train=False, download=download,\n",
    "                               transform=test_transform,\n",
    "                               target_transform=None)\n",
    "\n",
    "        if isinstance(train_labeled_dataset.targets, torch.Tensor):\n",
    "            train_labels = train_labeled_dataset.targets.numpy()\n",
    "        else:\n",
    "            train_labels = np.array(train_labeled_dataset.targets)\n",
    "\n",
    "        labeled_ind, unlabeled_ind = [], []\n",
    "\n",
    "        for cl in range(10):\n",
    "            class_indices = np.random.permutation(np.where(train_labels == cl)[0]).tolist()\n",
    "            labeled_ind.extend(class_indices[:num_labeled])\n",
    "            unlabeled_ind.extend(class_indices[num_labeled:])\n",
    "\n",
    "        return train_labeled_dataset, train_unlabeled_dataset, test_dataset, labeled_ind, unlabeled_ind\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
